{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, Optional, List\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General EDA\n",
    "\n",
    "def calculate_missing(df: pd.DataFrame, show_only_missing: bool = True, format_pct: bool = True):\n",
    "    \"\"\"Description\"\"\"\n",
    "    df_missing = (\n",
    "        df.isna().sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .to_frame('missing_count')\n",
    "        .assign(missing_pct = lambda x: x / len(df))\n",
    "        .rename_axis('feature')\n",
    "    )\n",
    "    \n",
    "    if show_only_missing:\n",
    "        df_missing = df_missing.query('missing_count>0')\n",
    "    \n",
    "    if format_pct:\n",
    "        df_missing = df_missing.style.format('{:.2%}', subset='missing_pct')\n",
    "    \n",
    "    return df_missing\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, Optional, List\n",
    "\n",
    "def compute_counts(\n",
    "    data: Union[pd.DataFrame, pd.Series, np.ndarray], \n",
    "    col: Optional[str] = None, \n",
    "    by: Optional[Union[str, List[str]]] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the absolute and relative frequency counts\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "        The input data. This can be a pandas DataFrame, Series, or a numpy array.\n",
    "    col : Optional[str], optional\n",
    "        The column name in the DataFrame for which to compute the counts. This parameter \n",
    "        is not used if the input data is a Series or numpy array. By default None.\n",
    "    by : Optional[Union[str, List[str]]], optional\n",
    "        The column name or list of column names to group the DataFrame by before computing counts. \n",
    "        This parameter is only used if the input data is a DataFrame. By default None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A DataFrame with the absolute ('abs_count') and relative ('rel_count') frequency \n",
    "        counts of the values in the specified column or the entire data set if 'col' is None.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    AssertionError\n",
    "        If the input data is not a DataFrame, Series, or numpy array.\n",
    "        If 'col' is None when input data is a DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if input data is either a dataframe, series, or numpy array\n",
    "    assert type(data) in (pd.DataFrame, pd.Series, np.ndarray)\n",
    "    \n",
    "    # Compute counts for dataframe\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        assert col is not None, 'The `col` parameter should not be None when the input data is a dataframe'\n",
    "        if by:\n",
    "            grp = data.groupby(by)\n",
    "            abs_count = grp[col].value_counts(normalize=False).to_frame('abs_count')\n",
    "            rel_count = grp[col].value_counts(normalize=True).to_frame('rel_count')\n",
    "        else:\n",
    "            abs_count = data[col].value_counts(normalize=False).to_frame('abs_count')\n",
    "            rel_count = data[col].value_counts(normalize=True).to_frame('rel_count')\n",
    "    # Compute counts for series or numpy array\n",
    "    else:\n",
    "        data = pd.Series(data) if not isinstance(data, pd.Series) else data\n",
    "        abs_count = data.value_counts(normalize=False).to_frame('abs_count')\n",
    "        rel_count = data.value_counts(normalize=True).to_frame('rel_count')\n",
    "    \n",
    "    # Aggregate absolute and relative counts\n",
    "    df_counts = pd.concat([abs_count, rel_count], axis=1)\n",
    "    \n",
    "    return df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association analysis\n",
    "\n",
    "def cramers_v(x, y, data=None, bias_correction=True):\n",
    "    \"\"\"\n",
    "    Compute Cramer's V statistic for measuring association between two categorical variables.\n",
    "\n",
    "    Parameters:\n",
    "    - x, y: two lists/arrays of categorical data or column names if data is provided\n",
    "    - data: Optional pandas DataFrame\n",
    "    - bias_correction: whether to apply bias correction, default is True\n",
    "\n",
    "    Returns:\n",
    "    - Cramer's V value\n",
    "    \"\"\"\n",
    "    if data is not None:\n",
    "        x = data[x]\n",
    "        y = data[y]\n",
    "        \n",
    "    contingency_table = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(contingency_table)[0]\n",
    "    n = contingency_table.sum().sum()\n",
    "    r, k = contingency_table.shape\n",
    "\n",
    "    if bias_correction:\n",
    "        phi2 = chi2 / n\n",
    "        phi2corr = max(0, phi2 - ((k-1)*(r-1)) / (n-1))\n",
    "        rcorr = r - ((r-1)**2) / (n-1)\n",
    "        kcorr = k - ((k-1)**2) / (n-1)\n",
    "        return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "    else:\n",
    "        return np.sqrt(chi2 / (n * min(k-1, r-1)))\n",
    "\n",
    "\n",
    "def goodman_kruskal_lambda(df, x_col, y_col):\n",
    "    \"\"\"\n",
    "    Compute Goodman-Kruskal's lambda for two categorical columns in a dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas dataframe containing the data\n",
    "    - x_col: name of the predictor variable column\n",
    "    - y_col: name of the response variable column\n",
    "\n",
    "    Returns:\n",
    "    - lambda_value: Goodman-Kruskal's lambda\n",
    "    \"\"\"\n",
    "    \n",
    "    # Overall proportion of most frequent category of y_col\n",
    "    overall_prop = df[y_col].value_counts(normalize=True).max()\n",
    "    \n",
    "    max_proportions = []\n",
    "    for x_val in df[x_col].unique():\n",
    "        # Proportion of most frequent category of y_col given a specific value of x_col\n",
    "        subset_prop = df[df[x_col] == x_val][y_col].value_counts(normalize=True).max()\n",
    "        max_proportions.append(subset_prop)\n",
    "    \n",
    "    lambda_value = (max(max_proportions) - overall_prop) / (1 - overall_prop)\n",
    "    return lambda_value\n",
    "\n",
    "\n",
    "# def goodman_kruskals_lambda(x, y, data=None):\n",
    "#     \"\"\"\n",
    "#     Compute Goodman and Kruskal's Lambda for nominal data.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - x: list/array of predictor values or column name if data is provided\n",
    "#     - y: list/array of target values or column name if data is provided\n",
    "#     - data: Optional pandas DataFrame\n",
    "    \n",
    "#     Returns:\n",
    "#     - lambda value\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Determine if data is provided or individual lists/arrays\n",
    "#     if data is not None:\n",
    "#         x = data[x]\n",
    "#         y = data[y]\n",
    "    \n",
    "#     # Create a crosstab\n",
    "#     ct = pd.crosstab(x, y)\n",
    "    \n",
    "#     # Proportion of errors without using the predictor\n",
    "#     total_entries = ct.sum().sum()\n",
    "#     max_in_each_row = ct.max(axis=1).sum()\n",
    "#     pe = (total_entries - max_in_each_row) / total_entries\n",
    "    \n",
    "#     # Proportion of errors using the predictor\n",
    "#     total_for_each_row = ct.sum(axis=1)\n",
    "#     max_proportion_for_each_row = ct.max(axis=1) / total_for_each_row\n",
    "#     po = 1 - max_proportion_for_each_row.mean()\n",
    "    \n",
    "#     # Compute lambda\n",
    "#     lambda_val = (pe - po) / pe\n",
    "#     return lambda_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
